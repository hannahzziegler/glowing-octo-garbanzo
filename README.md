# Scraping the Maryland State Employees Data Webpages

A disclaimer up top: I wanted to be way further into understanding how to get the data through deducing the problem to a single agency (in my case here, the state education department), but am headed out of town tonight (Saturday) and wanted to have this done before spring break officially began. I plan to keep toodling with things during the week as time permits.

For this assignment, my main goal was understanding the code of Derek's original scraper for this site, what needs to be changed for my specific purposes of this data that I'm pulling and trying to understand how to scrape the specifics that I need using a particular, single agency that I could scrape.

If nothing else, I think I have a much better understanding of this data and its information architecture through working through different parts of Derek's initial code and working to update/replicate things for just the state education department. What I'm mainly stuck on right now is getting just the

Something I didn't get around to this week (because man, pre-spring break work really seems to pile up) was updating portions of Derek's original scraper that pull down positions that aren't actually real. I think it has something to do with the provisions of the code where we are looking for contact information, such as lines like:
    (if row.find_all('td')[1].text.strip().upper() in ['GENERAL LISTING', 'TTY', 'TOLL FREE', 'MARYLAND TOLL FREE', 'GENERAL ASSISTANCE', 'FAX NUMBER', 'INFORMATION', 'TOLL FREE NUMBER', 'FACSIMILE', 'FACSIMILE NUMBER', 'FASCIMILE NUMBER', 'MAIN NUMBERS', 'MAIN NUMBER', 'GENERAL INFORMATION', 'GENERAL ASSEMBLY INFORMATION']:
                continue)

Those were the main instances where I could see things pulling down positions and pages that weren't actually home to employee information, as things like the "general information", "facsmile number" and other contact categories aren't typically routing to individual positions/jobs/people within the website's data, but instead a general toll number line/something similar to this. This is tricky because the information that doesn't have employee names/etc. in the table is structured the same way on each page as information about given vacancies, so I'm working to find solutions to how we can pull only employee information alone or how to distinguish that based on the HTML that we have to work with.

A main thing I was trying to accomplish this week (and didn't quite achieve) was getting sub-sub-agencies from the data. The scraper Derek had only pulled the agency information and subagency information, but many state employers also have additional pages associated with each subagency. For example, with our education department pages that I was workshopping and troubleshooting this week, there is:
    - A page for all the general agencies in the education department: https://www.doit.state.md.us/phonebook/level2offices.asp?AID=MSDE&offset=0
    - A page for each individual agency (in this example, the superintendant's office) that has employee information: https://www.doit.state.md.us/phonebook/OfficeSub.asp?OID=393
    - A page for each sub-sub agency within the superintendent's office and each other sub-agency that isn't currently getting scraped (in this example, the office of legal counsel from the state superintendent's office): https://www.doit.state.md.us/phonebook/OfficeSub.asp?OID=394

I'm having a hard time reducing these different pages to pull from into their most basic parts without hard-coding things into the scraper that won't be repurposable for other departments in the data. I frankly think I'm dealing with a fair amount of data overload just from the sheer number of pages of data to pull from and have hit a bit of a wall with what I've been trying to accomplish in the waning hours before spring break begins. 

There are also some offices that have links pulled down (such as the division of business services: https://www.doit.state.md.us/phonebook/OfficeSub.asp?OID=8066) that don't list any base employees on the page but do link to sub-agencies that have employees we will need to pull down. On a similar note, there are pages that don't link to any employee information whatsoever.

Something I'm wondering about in terms of troubleshooting/not making this scraper extremely convoluted is if there's a way to scrape from the searches for particularly vacant positions (seen here: https://www.doit.state.md.us/phonebook/IndListing.asp?FirstLetter=vacant&Submit=Search&offset=0) and seeing when things disappear or reappear on that page. Shreya had her scraper do something where it searched stuff in a search bar, so I don't know if that would be an easier approach to this task. Even scraping from the general search bar that has every single employee, their office and department in one place (i.e. https://www.doit.state.md.us/phonebook/AdvSearchResults.asp) seems a bit more feasible than dipping in and out of so many pages within the scraper as it works now/as I had outlined it in my head. I definitely plan to toy around with these possibilities over break and early in the week we come back to see if they're easier to work with, but like I said, I just wanted to get this assignment done before heading out for the week, so I'll leave my rambling about problems and troubleshooting at this. :-)